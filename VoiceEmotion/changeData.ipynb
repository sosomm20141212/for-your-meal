{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c676fb-2bfc-46c7-9dd8-886c1947a9c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_51588\\119768719.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1d04cf4-c662-4c9a-a2fd-d244826dd9eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 음성데이터 argumentation을 통해서 데이터 수 늘리기 및 오버피팅 방지\n",
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data):\n",
    "    return librosa.effects.time_stretch(data, rate=0.8)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitchs(data, sampling_rate, n_steps):\n",
    "    return librosa.effects.pitch_shift(y=data, sr=sampling_rate, n_steps=n_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd58da52-bd72-4eba-aead-b16c8ce1f021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features(data, sampling_rate):\n",
    "\n",
    "    result = np.array([])\n",
    "\n",
    "    # ZCR\n",
    "    # zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    # result=np.hstack((result, zcr)) # stacking horizontally\n",
    "    \n",
    "    # # Chroma_stft\n",
    "    # stft = np.abs(librosa.stft(data))\n",
    "    # chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sampling_rate).T, axis=0)\n",
    "    # result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
    "    \n",
    "    # # MFCC\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate).T, axis=0)\n",
    "    result = np.hstack((result, mfcc)) # stacking horizontally\n",
    "\n",
    "    # # Root Mean Square Value\n",
    "    # rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    # result = np.hstack((result, rms)) # stacking horizontally\n",
    "\n",
    "    # MelSpectogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sampling_rate).T, axis=0)\n",
    "    result = np.hstack((result, mel)) # stacking horizontally\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ca86988-1be3-42c5-96d9-39f2998768e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 음성의 특성을 추출한 데이터를 축적하는 함수 (Argumentation된 데이터도 같이)\n",
    "def get_features(path):\n",
    "    # duration과 offset은 각 오디오 파일의 시작과 끝에서 오디오가 없는 것을 처리\n",
    "    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "    sample_rate = 44100\n",
    "    # 원래데이터\n",
    "    res1 = extract_features(data, sample_rate)\n",
    "    result = np.array(res1)\n",
    "#     # 노이즈가 추가된 데이터\n",
    "    noise_data = noise(data)\n",
    "    res2 = extract_features(noise_data, sample_rate)\n",
    "    result = np.vstack((result, res2)) # 병렬적으로 추가\n",
    "\n",
    "#     # 피칭및 스트레칭된 데이터\n",
    "    new_data = stretch(data)\n",
    "    data_stretch_pitch = pitchs(new_data, sample_rate, 0.7)\n",
    "    res3 = extract_features(data_stretch_pitch, sample_rate)\n",
    "    result = np.vstack((result, res3)) # 병렬적으로 추가\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "803daa7b-b783-44e3-804d-04209b3c4933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "feature = get_features(\"soundData/test/test.wav\")\n",
    "for ele in feature:\n",
    "    X.append(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f21f7c7-7e9a-49e7-8abf-662a0752be9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Features = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d64a1245-d748-4b5c-aa22-f1c48ef2ba64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = Features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ecbccec-b22f-4463-9718-f7a0423a2f5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 148)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c6aca88-1d2d-49d0-8ec5-769ab2b967ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d89109de-86ca-405f-bffd-488c44f1bdba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 148)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a8c4a00-3667-4f8a-a1d2-7a5b4bc18de0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.expand_dims(x, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89d4d195-4a12-4d5e-a1a0-7979d1b84cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = load_model('sound_classifier_model_MFCC_MEL_44100(version4).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef4088e7-55c4-47dc-a5df-46effe2460f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 513ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "314d0025-7101-4188-b596-158957f15b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = np.array(['anger', 'disgust', 'fear', 'happiness', 'neutral', 'sadness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b5cb4db-3934-4779-bc72-e9a3427c1e89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(y).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3451498-eb87-4bd6-8d19-8ac8f853bdc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = encoder.inverse_transform(pred_test)\n",
    "df = pd.DataFrame(columns=['Predicted Labels'])\n",
    "df['Predicted Labels'] = y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff1bc905-14f6-495a-8453-cedfbbaadb02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    neutral\n",
       "1    neutral\n",
       "2    disgust\n",
       "Name: Predicted Labels, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Predicted Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2c87501-d67c-4184-905d-516b9f775611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['neutral'],\n",
       "       ['neutral'],\n",
       "       ['disgust']], dtype='<U9')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f435b9-7a96-43c6-ba13-47e7c3aba652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52da910-c5d7-47e8-8101-b0801ee8804e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
